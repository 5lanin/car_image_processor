{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2c6fa3a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/damian/Projects/minRF/.venv/lib/python3.10/site-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.\n",
      "  import pynvml  # type: ignore[import]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import requests\n",
    "import csv\n",
    "import pandas as pd\n",
    "import torch\n",
    "from ultralytics import YOLO\n",
    "import supervision as sv\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "# MODEL_PATH = '../00_model_checkpoints/yolov10x.pt'\n",
    "MODEL_PATH = '/mnt/damian/Projects/car_image_processor/postprocessing/yolo11x.pt'\n",
    "\n",
    "category_dict = {\n",
    "    0: 'person', 1: 'bicycle', 2: 'car', 3: 'motorcycle', 4: 'airplane', 5: 'bus',\n",
    "    6: 'train', 7: 'truck', 8: 'boat', 9: 'traffic light', 10: 'fire hydrant',\n",
    "    11: 'stop sign', 12: 'parking meter', 13: 'bench', 14: 'bird', 15: 'cat',\n",
    "    16: 'dog', 17: 'horse', 18: 'sheep', 19: 'cow', 20: 'elephant', 21: 'bear',\n",
    "    22: 'zebra', 23: 'giraffe', 24: 'backpack', 25: 'umbrella', 26: 'handbag',\n",
    "    27: 'tie', 28: 'suitcase', 29: 'frisbee', 30: 'skis', 31: 'snowboard',\n",
    "    32: 'sports ball', 33: 'kite', 34: 'baseball bat', 35: 'baseball glove',\n",
    "    36: 'skateboard', 37: 'surfboard', 38: 'tennis racket', 39: 'bottle',\n",
    "    40: 'wine glass', 41: 'cup', 42: 'fork', 43: 'knife', 44: 'spoon', 45: 'bowl',\n",
    "    46: 'banana', 47: 'apple', 48: 'sandwich', 49: 'orange', 50: 'broccoli',\n",
    "    51: 'carrot', 52: 'hot dog', 53: 'pizza', 54: 'donut', 55: 'cake',\n",
    "    56: 'chair', 57: 'couch', 58: 'potted plant', 59: 'bed', 60: 'dining table',\n",
    "    61: 'toilet', 62: 'tv', 63: 'laptop', 64: 'mouse', 65: 'remote', 66: 'keyboard',\n",
    "    67: 'cell phone', 68: 'microwave', 69: 'oven', 70: 'toaster', 71: 'sink',\n",
    "    72: 'refrigerator', 73: 'book', 74: 'clock', 75: 'vase', 76: 'scissors',\n",
    "    77: 'teddy bear', 78: 'hair drier', 79: 'toothbrush'\n",
    "}\n",
    "\n",
    "class YOLO_helper:\n",
    "    def __init__(self, device=\"cuda\"):\n",
    "        # torch.serialization.add_safe_globals([YOLO])\n",
    "        # torch.serialization.safe_globals([YOLO])\n",
    "        self.model = YOLO(MODEL_PATH).to(device)\n",
    "        self.model.eval()\n",
    "\n",
    "    def label_single_image(self, pil_img):\n",
    "        cv2_image = cv2.cvtColor(np.array(pil_img), cv2.COLOR_RGB2BGR) \n",
    "        # scale image to 640 on the longest side\n",
    "        scale = 640 / max(cv2_image.shape[:2])\n",
    "        cv2_image = cv2.resize(cv2_image, (0, 0), fx=scale, fy=scale)\n",
    "        results = self.model(source=cv2_image, conf=0.25, verbose=False)[0]\n",
    "        detections = sv.Detections.from_ultralytics(results)\n",
    "        labels = [\n",
    "            f\"{category_dict[class_id]}:{confidence:.2f}\"\n",
    "            for class_id, confidence in zip(detections.class_id, detections.confidence)\n",
    "        ]\n",
    "        return labels\n",
    "\n",
    "    def label_batch_images(self, pil_images, single_label_per_image=False):\n",
    "        \"\"\"\n",
    "        Label a batch of images using the YOLO model.\n",
    "        Args:\n",
    "            pil_images (list of PIL.Image): List of images to label.\n",
    "            single_label_per_image (bool): If True, return only the first label for each image.\n",
    "        Returns:\n",
    "            list of str: List of labels for each image.\n",
    "        \"\"\"\n",
    "        cv2_images = [cv2.cvtColor(np.array(pil_img), cv2.COLOR_RGB2BGR) for pil_img in pil_images]\n",
    "        results = self.model(source=cv2_images, conf=0.25, verbose=False)\n",
    "        labels = []\n",
    "        for result in results:\n",
    "            detections = sv.Detections.from_ultralytics(result)\n",
    "            if single_label_per_image and len(detections.class_id) > 0:\n",
    "                if detections.confidence[0] < 0.89:\n",
    "                    internal_labels = \" \"\n",
    "                else:\n",
    "                    internal_labels = f\"{category_dict[detections.class_id[0]]}\"\n",
    "            else:\n",
    "                labels_single_image = [\n",
    "                    f\"{category_dict[class_id]}:{confidence:.2f}\"\n",
    "                    for class_id, confidence in zip(detections.class_id, detections.confidence)\n",
    "                    ]\n",
    "                internal_labels = \"\"\n",
    "                for label in labels_single_image:\n",
    "                    if len(internal_labels) > 0:\n",
    "                        internal_labels += \", \"\n",
    "                    internal_labels += label #.split(\":\")[0]\n",
    "                if len(internal_labels) == 0:\n",
    "                    internal_labels = \" \"\n",
    "            labels.append(internal_labels)\n",
    "        return labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b0835cfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "import uuid\n",
    "import tempfile\n",
    "from PIL import Image\n",
    "from rembg import remove\n",
    "import io\n",
    "import time\n",
    "import json\n",
    "import random\n",
    "\n",
    "def download_image(url, save_path=None, max_retries=3):\n",
    "    \"\"\"Download an image from a URL and return as PIL Image with retry logic\"\"\"\n",
    "    headers = {\n",
    "        'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36',\n",
    "        'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,*/*;q=0.8',\n",
    "        'Accept-Language': 'en-US,en;q=0.5',\n",
    "        'Referer': 'https://www.autoevolution.com/',\n",
    "        'DNT': '1',\n",
    "        'Connection': 'keep-alive',\n",
    "        'Upgrade-Insecure-Requests': '1',\n",
    "        'Cache-Control': 'max-age=0',\n",
    "    }\n",
    "    \n",
    "    for attempt in range(max_retries):\n",
    "        try:\n",
    "            response = requests.get(url, headers=headers, timeout=15)\n",
    "            if response.status_code == 200:\n",
    "                img = Image.open(io.BytesIO(response.content))\n",
    "                if save_path:\n",
    "                    img.save(save_path)\n",
    "                return img\n",
    "            elif response.status_code == 403:\n",
    "                print(f\"Access forbidden (403) for {url}, retry {attempt+1}/{max_retries}\")\n",
    "                time.sleep(2 ** attempt)  # Exponential backoff\n",
    "            else:\n",
    "                print(f\"Failed to download image, status code: {response.status_code}\")\n",
    "                break  # Don't retry for non-403 errors\n",
    "        except Exception as e:\n",
    "            print(f\"Error downloading image from {url}: {e}\")\n",
    "            time.sleep(2 ** attempt)  # Exponential backoff\n",
    "    return None\n",
    "\n",
    "def remove_background_and_rescale(img, target_size=512):\n",
    "    \"\"\"Remove background and rescale image to fit within target_size without distortion\"\"\"\n",
    "    # Remove background\n",
    "    img_no_bg = remove(img)\n",
    "    \n",
    "    # Get alpha channel for object dimensions\n",
    "    alpha = np.array(img_no_bg.getchannel('A'))\n",
    "    # Find object bounding box\n",
    "    coords = np.argwhere(alpha > 0)\n",
    "    if len(coords) == 0:  # No foreground object found\n",
    "        return None\n",
    "        \n",
    "    y_min, x_min = coords.min(axis=0)\n",
    "    y_max, x_max = coords.max(axis=0)\n",
    "    \n",
    "    # Crop to object bounding box\n",
    "    cropped = img_no_bg.crop((x_min, y_min, x_max, y_max))\n",
    "    \n",
    "    # Calculate scaling factor to fit within target size\n",
    "    width, height = cropped.size\n",
    "    scale_factor = min(target_size / width, target_size / height)\n",
    "    \n",
    "    # Resize while maintaining aspect ratio\n",
    "    new_width = int(width * scale_factor)\n",
    "    new_height = int(height * scale_factor)\n",
    "    resized = cropped.resize((new_width, new_height), Image.LANCZOS)\n",
    "    \n",
    "    # Create new image with white background of target size\n",
    "    final_img = Image.new('RGBA', (target_size, target_size), (0, 0, 0, 0))\n",
    "    \n",
    "    # Paste resized image in center\n",
    "    paste_x = (target_size - new_width) // 2\n",
    "    paste_y = (target_size - new_height) // 2\n",
    "    final_img.paste(resized, (paste_x, paste_y), resized)\n",
    "    \n",
    "    return final_img\n",
    "\n",
    "def process_image_batch(image_urls, metadata_rows, yolo_helper, temp_dir, output_dir, metadata_file, gpu_batch_size=64, metadata_row_file_limit=25):\n",
    "    \"\"\"Process all available images from each URL list, using batching for YOLO inference\"\"\"\n",
    "    os.makedirs(temp_dir, exist_ok=True)\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    \n",
    "    # Step 1: Download all available images from all URL lists\n",
    "    all_images = []  # List to store all downloaded images\n",
    "    all_temp_paths = []  # List to store all temporary file paths\n",
    "    all_metadata_indices = []  # List to store metadata row indices for each image\n",
    "    all_original_urls = []  # List to store the original URL for each image\n",
    "    \n",
    "    print(f\"Starting to download images from {len(image_urls)} metadata rows\")\n",
    "    for i, (url_list, metadata) in enumerate(zip(image_urls, metadata_rows)):\n",
    "        urls = [url.strip() for url in url_list.split(',')]\n",
    "        random.shuffle(urls)  # Randomize to distribute load\n",
    "        \n",
    "        # Try to download each image in the URL list\n",
    "        successful_downloads = 0\n",
    "        \n",
    "        for j, url in enumerate(urls):\n",
    "            if successful_downloads >= metadata_row_file_limit:  # Limit to 25 successful downloads per metadata row\n",
    "                break\n",
    "                \n",
    "            temp_path = os.path.join(temp_dir, f\"temp_{i}_{j}_{uuid.uuid4().hex[:6]}.jpg\")\n",
    "            img = download_image(url, temp_path)\n",
    "            \n",
    "            if img is not None:\n",
    "                all_images.append(img)\n",
    "                all_temp_paths.append(temp_path)\n",
    "                all_metadata_indices.append(i)\n",
    "                all_original_urls.append(url)\n",
    "                successful_downloads += 1\n",
    "            else:\n",
    "                # Remove failed temp file if it exists\n",
    "                if os.path.exists(temp_path):\n",
    "                    os.remove(temp_path)\n",
    "            \n",
    "            # Small delay between downloads from the same metadata row\n",
    "            time.sleep(0.5)\n",
    "        \n",
    "        # Report progress for this metadata row\n",
    "        if successful_downloads > 0:\n",
    "            print(f\"Row {i}: Downloaded {successful_downloads} images successfully\")\n",
    "        else:\n",
    "            print(f\"Row {i}: Failed to download any images\")\n",
    "            \n",
    "        # Add a small delay between processing different metadata rows\n",
    "        time.sleep(1)\n",
    "    \n",
    "    if not all_images:\n",
    "        print(\"No images were successfully downloaded in this batch\")\n",
    "        return\n",
    "    \n",
    "    print(f\"Successfully downloaded {len(all_images)} images in total\")\n",
    "    \n",
    "    # Step 2: Process downloaded images in batches with YOLO\n",
    "    car_metadata = []  # List to store metadata for car images\n",
    "    \n",
    "    # Process images in batches to avoid GPU memory issues\n",
    "    for batch_start in range(0, len(all_images), gpu_batch_size):\n",
    "        batch_end = min(batch_start + gpu_batch_size, len(all_images))\n",
    "        batch_images = all_images[batch_start:batch_end]\n",
    "        batch_indices = all_metadata_indices[batch_start:batch_end]\n",
    "        batch_urls = all_original_urls[batch_start:batch_end]\n",
    "        batch_paths = all_temp_paths[batch_start:batch_end]\n",
    "        \n",
    "        print(f\"Processing YOLO batch {batch_start//gpu_batch_size + 1}/{(len(all_images)+gpu_batch_size-1)//gpu_batch_size} with {len(batch_images)} images\")\n",
    "        \n",
    "        # Detect cars in this batch\n",
    "        labels = yolo_helper.label_batch_images(batch_images, single_label_per_image=True)\n",
    "        \n",
    "        # Process each image in the batch based on its label\n",
    "        for i, (img, label, metadata_idx, url, temp_path) in enumerate(zip(batch_images, labels, batch_indices, batch_urls, batch_paths)):\n",
    "            if 'car' in label.lower() or 'truck' in label.lower():\n",
    "                print(f\"Processing image with label: {label}\")\n",
    "                # Remove background and rescale\n",
    "                processed_img = remove_background_and_rescale(img)\n",
    "                if processed_img is None:\n",
    "                    print(\"  Failed to remove background or no foreground detected\")\n",
    "                    continue\n",
    "                    \n",
    "                # Generate unique filename\n",
    "                unique_id = str(uuid.uuid4())[:8]\n",
    "                brand = metadata_rows[metadata_idx]['brand'].replace(' ', '_')\n",
    "                model = metadata_rows[metadata_idx]['model'].replace(' ', '_')\n",
    "                year = metadata_rows[metadata_idx]['from_year']\n",
    "                \n",
    "                filename = f\"{brand}_{model}_{year}_{unique_id}.png\"\n",
    "                output_path = os.path.join(output_dir, filename)\n",
    "                \n",
    "                # Save processed image\n",
    "                processed_img.save(output_path)\n",
    "                \n",
    "                # Add metadata\n",
    "                metadata_entry = metadata_rows[metadata_idx].copy()\n",
    "                metadata_entry['original_url'] = url\n",
    "                metadata_entry['saved_filename'] = filename\n",
    "                metadata_entry['detection_label'] = label\n",
    "                car_metadata.append(metadata_entry)\n",
    "                \n",
    "                print(f\"Saved car image: {filename}\")\n",
    "            else:\n",
    "                print(f\"Skipping image with label: {label}\")\n",
    "        \n",
    "        # Clean up temporary files for this batch\n",
    "        for path in batch_paths:\n",
    "            if os.path.exists(path):\n",
    "                os.remove(path)\n",
    "    \n",
    "    # Step 3: Save metadata to CSV\n",
    "    if car_metadata:\n",
    "        with open(metadata_file, 'a', newline='') as f:\n",
    "            writer = csv.DictWriter(f, fieldnames=car_metadata[0].keys())\n",
    "            if os.stat(metadata_file).st_size == 0:  # File is empty, write header\n",
    "                writer.writeheader()\n",
    "            writer.writerows(car_metadata)\n",
    "        print(f\"Saved metadata for {len(car_metadata)} car images\")\n",
    "    else:\n",
    "        print(\"No car images were found in the downloaded images\")\n",
    "    \n",
    "    print(f\"Batch processing complete. Processed {len(all_images)} images, found {len(car_metadata)} cars.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7b898ebf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing metadata batch 1/763 (rows 0-4)\n",
      "Starting to download images from 5 metadata rows\n",
      "Row 0: Downloaded 24 images successfully\n",
      "Row 1: Downloaded 25 images successfully\n",
      "Row 2: Downloaded 25 images successfully\n",
      "Row 3: Downloaded 25 images successfully\n",
      "Row 4: Downloaded 25 images successfully\n",
      "Successfully downloaded 124 images in total\n",
      "Processing YOLO batch 1/4 with 32 images\n",
      "Skipping image with label:  \n",
      "Skipping image with label:  \n",
      "Processing image with label: car\n",
      "Saved car image: AC_AC__428_Convertible_1966_b0ea1119.png\n",
      "Skipping image with label:  \n",
      "Processing image with label: truck\n",
      "Saved car image: AC_AC__428_Convertible_1966_528631a6.png\n",
      "Skipping image with label:  \n",
      "Skipping image with label:  \n",
      "Processing image with label: car\n",
      "Saved car image: AC_AC__428_Convertible_1966_bba604d6.png\n",
      "Skipping image with label:  \n",
      "Skipping image with label:  \n",
      "Skipping image with label: motorcycle\n",
      "Skipping image with label:  \n",
      "Skipping image with label:  \n",
      "Skipping image with label:  \n",
      "Processing image with label: car\n",
      "Saved car image: AC_AC__428_Convertible_1966_788552ee.png\n",
      "Processing image with label: car\n",
      "Saved car image: AC_AC__428_Convertible_1966_be914b44.png\n",
      "Skipping image with label:  \n",
      "Skipping image with label: motorcycle\n",
      "Processing image with label: car\n",
      "Saved car image: AC_AC__428_Convertible_1966_8ed860d3.png\n",
      "Processing image with label: car\n",
      "Saved car image: AC_AC__428_Convertible_1966_65a96e82.png\n",
      "Skipping image with label:  \n",
      "Processing image with label: car\n",
      "Saved car image: AC_AC__428_Convertible_1966_a1a73dd6.png\n",
      "Skipping image with label:  \n",
      "Skipping image with label:  \n",
      "Skipping image with label:  \n",
      "Skipping image with label:  \n",
      "Processing image with label: car\n",
      "Saved car image: ACURA_ACURA_MDX_2001_cbd7faf3.png\n",
      "Processing image with label: car\n",
      "Saved car image: ACURA_ACURA_MDX_2001_6eee29df.png\n",
      "Skipping image with label: chair\n",
      "Skipping image with label:  \n",
      "Skipping image with label:  \n",
      "Processing image with label: car\n",
      "Saved car image: ACURA_ACURA_MDX_2001_27829bcd.png\n",
      "Processing YOLO batch 2/4 with 32 images\n",
      "Processing image with label: car\n",
      "Saved car image: ACURA_ACURA_MDX_2001_b9155eda.png\n",
      "Skipping image with label: chair\n",
      "Skipping image with label:  \n",
      "Processing image with label: car\n",
      "Saved car image: ACURA_ACURA_MDX_2001_a7d7a847.png\n",
      "Processing image with label: car\n",
      "Saved car image: ACURA_ACURA_MDX_2001_4b6dd1e1.png\n",
      "Skipping image with label:  \n",
      "Processing image with label: car\n",
      "Saved car image: ACURA_ACURA_MDX_2001_71585151.png\n",
      "Processing image with label: car\n",
      "Saved car image: ACURA_ACURA_MDX_2001_47b3b32d.png\n",
      "Skipping image with label:  \n",
      "Skipping image with label:  \n",
      "Skipping image with label:  \n",
      "Skipping image with label:  \n",
      "Processing image with label: car\n",
      "Saved car image: ACURA_ACURA_MDX_2001_7fa4b870.png\n",
      "Skipping image with label:  \n",
      "Processing image with label: car\n",
      "Saved car image: ACURA_ACURA_MDX_2001_e28e7650.png\n",
      "Skipping image with label:  \n",
      "Processing image with label: car\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 49\u001b[0m\n\u001b[1;32m     46\u001b[0m batch_urls \u001b[38;5;241m=\u001b[39m image_urls[start_idx:end_idx]\n\u001b[1;32m     47\u001b[0m batch_metadata \u001b[38;5;241m=\u001b[39m metadata_rows[start_idx:end_idx]\n\u001b[0;32m---> 49\u001b[0m \u001b[43mprocess_image_batch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch_urls\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_metadata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43myolo_helper\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtemp_dir\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput_dir\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetadata_file\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgpu_batch_size\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     51\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m test_batch:\n\u001b[1;32m     52\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTest batch completed. Set test_batch = False to process all images.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[0;32mIn[2], line 156\u001b[0m, in \u001b[0;36mprocess_image_batch\u001b[0;34m(image_urls, metadata_rows, yolo_helper, temp_dir, output_dir, metadata_file, gpu_batch_size, metadata_row_file_limit)\u001b[0m\n\u001b[1;32m    154\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mProcessing image with label: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlabel\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    155\u001b[0m \u001b[38;5;66;03m# Remove background and rescale\u001b[39;00m\n\u001b[0;32m--> 156\u001b[0m processed_img \u001b[38;5;241m=\u001b[39m \u001b[43mremove_background_and_rescale\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    157\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m processed_img \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    158\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m  Failed to remove background or no foreground detected\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[0;32mIn[2], line 46\u001b[0m, in \u001b[0;36mremove_background_and_rescale\u001b[0;34m(img, target_size)\u001b[0m\n\u001b[1;32m     44\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Remove background and rescale image to fit within target_size without distortion\"\"\"\u001b[39;00m\n\u001b[1;32m     45\u001b[0m \u001b[38;5;66;03m# Remove background\u001b[39;00m\n\u001b[0;32m---> 46\u001b[0m img_no_bg \u001b[38;5;241m=\u001b[39m \u001b[43mremove\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     48\u001b[0m \u001b[38;5;66;03m# Get alpha channel for object dimensions\u001b[39;00m\n\u001b[1;32m     49\u001b[0m alpha \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray(img_no_bg\u001b[38;5;241m.\u001b[39mgetchannel(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mA\u001b[39m\u001b[38;5;124m'\u001b[39m))\n",
      "File \u001b[0;32m/mnt/damian/Projects/minRF/.venv/lib/python3.10/site-packages/rembg/bg.py:279\u001b[0m, in \u001b[0;36mremove\u001b[0;34m(data, alpha_matting, alpha_matting_foreground_threshold, alpha_matting_background_threshold, alpha_matting_erode_size, session, only_mask, post_process_mask, bgcolor, force_return_bytes, *args, **kwargs)\u001b[0m\n\u001b[1;32m    276\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m session \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    277\u001b[0m     session \u001b[38;5;241m=\u001b[39m new_session(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mu2net\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m--> 279\u001b[0m masks \u001b[38;5;241m=\u001b[39m \u001b[43msession\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    280\u001b[0m cutouts \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m    282\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m mask \u001b[38;5;129;01min\u001b[39;00m masks:\n",
      "File \u001b[0;32m/mnt/damian/Projects/minRF/.venv/lib/python3.10/site-packages/rembg/sessions/u2net.py:29\u001b[0m, in \u001b[0;36mU2netSession.predict\u001b[0;34m(self, img, *args, **kwargs)\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mpredict\u001b[39m(\u001b[38;5;28mself\u001b[39m, img: PILImage, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m List[PILImage]:\n\u001b[1;32m     18\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     19\u001b[0m \u001b[38;5;124;03m    Predicts the output masks for the input image using the inner session.\u001b[39;00m\n\u001b[1;32m     20\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[38;5;124;03m        List[PILImage]: The list of output masks.\u001b[39;00m\n\u001b[1;32m     28\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m---> 29\u001b[0m     ort_outs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minner_session\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     30\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     31\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnormalize\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     32\u001b[0m \u001b[43m            \u001b[49m\u001b[43mimg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0.485\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0.456\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0.406\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0.229\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0.224\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0.225\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m320\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m320\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     33\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     34\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     36\u001b[0m     pred \u001b[38;5;241m=\u001b[39m ort_outs[\u001b[38;5;241m0\u001b[39m][:, \u001b[38;5;241m0\u001b[39m, :, :]\n\u001b[1;32m     38\u001b[0m     ma \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mmax(pred)\n",
      "File \u001b[0;32m/mnt/damian/Projects/minRF/.venv/lib/python3.10/site-packages/onnxruntime/capi/onnxruntime_inference_collection.py:273\u001b[0m, in \u001b[0;36mSession.run\u001b[0;34m(self, output_names, input_feed, run_options)\u001b[0m\n\u001b[1;32m    271\u001b[0m     output_names \u001b[38;5;241m=\u001b[39m [output\u001b[38;5;241m.\u001b[39mname \u001b[38;5;28;01mfor\u001b[39;00m output \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_outputs_meta]\n\u001b[1;32m    272\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 273\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sess\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43moutput_names\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_feed\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrun_options\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    274\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m C\u001b[38;5;241m.\u001b[39mEPFail \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[1;32m    275\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_enable_fallback:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Load data (assuming data is already loaded from previous cell)\n",
    "if 'data' not in globals():\n",
    "    data = pd.read_csv('./output/data_full.csv')\n",
    "\n",
    "# Select required fields\n",
    "fields = ['brand', 'model', 'from_year', 'to_year', 'body_style', 'segment', 'title', 'description', 'model_url']\n",
    "metadata_fields = {field: data[field].tolist() for field in fields if field in data.columns}\n",
    "\n",
    "# Create list of metadata dictionaries\n",
    "metadata_rows = []\n",
    "for i in range(len(data)):\n",
    "    row = {field: metadata_fields[field][i] for field in fields if field in metadata_fields}\n",
    "    metadata_rows.append(row)\n",
    "\n",
    "# Extract image URLs\n",
    "image_urls = data['image_urls'].tolist()\n",
    "\n",
    "# Initialize YOLO helper\n",
    "yolo_helper = YOLO_helper()\n",
    "\n",
    "# Setup directories\n",
    "temp_dir = './temp_downloads'\n",
    "output_dir = './car_images'\n",
    "metadata_file = './car_images_metadata.csv'\n",
    "\n",
    "os.makedirs(temp_dir, exist_ok=True)\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# Create empty metadata file\n",
    "if not os.path.exists(metadata_file):\n",
    "    with open(metadata_file, 'w', newline='') as f:\n",
    "        pass  # Create empty file\n",
    "\n",
    "# Define batch sizes\n",
    "index_batch_size = 5  # Number of metadata rows to process at once\n",
    "gpu_batch_size = 32   # Number of images to process with YOLO at once\n",
    "total_images = len(image_urls)\n",
    "\n",
    "# Process the first batch as a test\n",
    "test_batch = True\n",
    "\n",
    "for start_idx in range(0, total_images, index_batch_size):\n",
    "    end_idx = min(start_idx + index_batch_size, total_images)\n",
    "    print(f\"Processing metadata batch {start_idx//index_batch_size + 1}/{(total_images+index_batch_size-1)//index_batch_size} (rows {start_idx}-{end_idx-1})\")\n",
    "    \n",
    "    batch_urls = image_urls[start_idx:end_idx]\n",
    "    batch_metadata = metadata_rows[start_idx:end_idx]\n",
    "    \n",
    "    process_image_batch(batch_urls, batch_metadata, yolo_helper, temp_dir, output_dir, metadata_file, gpu_batch_size)\n",
    "    \n",
    "    if test_batch:\n",
    "        print(\"Test batch completed. Set test_batch = False to process all images.\")\n",
    "        break\n",
    "    \n",
    "    # Add a delay between batches to avoid overwhelming servers\n",
    "    time.sleep(5)\n",
    "\n",
    "# Clean up temp directory when done\n",
    "if os.path.exists(temp_dir):\n",
    "    shutil.rmtree(temp_dir)\n",
    "\n",
    "print(f\"Processing complete. Car images saved to {output_dir} with metadata in {metadata_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da2cc8ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set to False to process all remaining images\n",
    "test_batch = False\n",
    "\n",
    "if not test_batch:\n",
    "    # Continue processing from where we left off\n",
    "    # First, check how many images we've already processed\n",
    "    processed_count = 0\n",
    "    processed_indexes = set()\n",
    "    \n",
    "    if os.path.exists(metadata_file) and os.path.getsize(metadata_file) > 0:\n",
    "        try:\n",
    "            # Load the metadata to see what we've already processed\n",
    "            processed_df = pd.read_csv(metadata_file)\n",
    "            # Extract original URLs to identify which rows were processed\n",
    "            for url in processed_df['original_url']:\n",
    "                # Find which row contains this URL\n",
    "                for idx, url_list in enumerate(image_urls):\n",
    "                    if url in url_list:\n",
    "                        processed_indexes.add(idx)\n",
    "            processed_count = len(processed_indexes)\n",
    "            print(f\"Found {processed_count} already processed items\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error reading metadata file: {e}\")\n",
    "            processed_count = 0\n",
    "    \n",
    "    # Process in batches, skipping already processed ones\n",
    "    index_batch_size = 10   # Keep small batch size for metadata rows\n",
    "    gpu_batch_size = 64    # GPU batch size for YOLO processing\n",
    "    \n",
    "    # Create a list of indices to process (skip already processed ones)\n",
    "    indices_to_process = [i for i in range(total_images) if i not in processed_indexes]\n",
    "    print(f\"Processing {len(indices_to_process)} remaining items\")\n",
    "    \n",
    "    # Process in random order to distribute across different model types\n",
    "    random.shuffle(indices_to_process)\n",
    "    \n",
    "    for batch_start in range(0, len(indices_to_process), index_batch_size):\n",
    "        batch_indices = indices_to_process[batch_start:batch_start+index_batch_size]\n",
    "        print(f\"Processing batch {batch_start//index_batch_size + 1}/{(len(indices_to_process)+index_batch_size-1)//index_batch_size}\")\n",
    "        \n",
    "        batch_urls = [image_urls[i] for i in batch_indices]\n",
    "        batch_metadata = [metadata_rows[i] for i in batch_indices]\n",
    "        \n",
    "        process_image_batch(batch_urls, batch_metadata, yolo_helper, temp_dir, output_dir, metadata_file, gpu_batch_size)\n",
    "        \n",
    "        # Add a delay between batches to avoid overwhelming servers\n",
    "        time.sleep(5)\n",
    "    \n",
    "    # Clean up temp directory when done\n",
    "    if os.path.exists(temp_dir):\n",
    "        shutil.rmtree(temp_dir)\n",
    "    \n",
    "    print(f\"Processing complete. Car images saved to {output_dir} with metadata in {metadata_file}\")\n",
    "else:\n",
    "    print(\"Set test_batch = False to process all remaining images.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bce0ea69",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check results\n",
    "if os.path.exists(metadata_file):\n",
    "    car_metadata_df = pd.read_csv(metadata_file)\n",
    "    print(f\"Total car images saved: {len(car_metadata_df)}\")\n",
    "    print(\"\\nSample metadata:\")\n",
    "    display(car_metadata_df.head())\n",
    "    \n",
    "    # Display a few sample images\n",
    "    if len(car_metadata_df) > 0:\n",
    "        from IPython.display import display, Image as IPImage\n",
    "        print(\"\\nSample images:\")\n",
    "        sample_files = car_metadata_df['saved_filename'].sample(min(5, len(car_metadata_df))).tolist()\n",
    "        for file in sample_files:\n",
    "            img_path = os.path.join(output_dir, file)\n",
    "            if os.path.exists(img_path):\n",
    "                display(IPImage(filename=img_path, width=300))\n",
    "else:\n",
    "    print(\"No metadata file found. Run the processing cells first.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
